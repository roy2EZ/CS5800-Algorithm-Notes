Class 1 05/06/2019

Introduction
Asymptotic analysis
Solving recursions

Fibonacci numbers
Fibonacci numbers (Exponential Algorithm)
0, 1, 1, 2, 3, 5, 8, 13, 21
a0, a1, a3, a3, a4, a5, a6, a7

an = an-1 + an-2
a0 = 0
a1 = 1
Code
fib1(int n) {
    if (n == 0 || n == 1) {
        return n;
    }
    return fib1(n-1) + fib1(n-2);
}
Time Complexity
Answer O(2^n)

Less intuitive, not like

for i in range(10):
    a[i] = a[i-1] + 2
Recursion Tree
$ T(n) = \text {runtime of fib1(n)}$

              T(n)
       /              \
    T(n-1)           T(n-2)
   /     \           /     \
T(n-2)   T(n-3)    T(n-3)   T(n-4)
            ......
T(1)    T(0)    T(1)    T(0) ...
When hit 0 or 1, the recursion ends.

            /\
           /  \
          /____\
         /     /
        /  _ /
       / _/
      /_/
left side = n
right side = n/2

T(n) = num of nodes in this recursion tree
in first half of this tree
            /\
           /  \
          /____\
num of nodes = 2^k-1 = 2 ^ (n/2) - 1
Thus we have

$ 2 ^ {n/2} <= T(n) <= 2 ^ n $

Therefore

$ 2 ^ {n/2} = (\sqrt {2}) ^ n ~= 1.4n $

Clearly, this is a bad time complexity algorithm.

                  T(n)
           /              \
        T(n-1)           T(n-2)
       /     \           /     \
    T(n-2)   T(n-3)    T(n-3)   T(n-4)

There are a lot of repetition in the process of calculation. 

e.g. T(n-2) T(n-3)
Linear algorithm
Code
fib2(int n) {
    int[] A = new int[n];
    A[0] = 0; A[1] = 1;
    for (int i = 2; i <= n; i++) {
        A[i] = A[i-1] + A[i-2];
    }
    return A[n];
}
Time Complexity
Linear time: O(n)

Constant space algorithm
Code
fib2(int n) {
    int[] A = new int[2];
    A[0] = 0; A[1] = 1;
    for (int i = 2; i <= n; i++) {
        A[i%2] = A[(i-1)%2] + A[(i-2)%2];
    }
    return A[n%2];
}
Analysis
i varies between 0 and 1
A[1] = A[0] + A[1]
A[0] = A[1] + A[0]
Matrix solution
Idea
$$
A = \left[
\begin{matrix}
1 & 1 \
1 & 0
\end{matrix}
\right]
$$

$$
A^2 = \left[
\begin{matrix}
1 & 1 \
1 & 0
\end{matrix}
\right] *
\left[
\begin{matrix}
1 & 1 \
1 & 0
\end{matrix}
\right] =
\left[
\begin{matrix}
2 & 1 \
1 & 1
\end{matrix}
\right] =
\left[
\begin{matrix}
1 & 1 \
1 & 0
\end{matrix}
\right]
$$

A = | 1  1 | = | a2  a1 |
    | 1  0 |   | a1  a0 |

A^2 = | 1  1 |    | 1  1 |      | 2  1 |   | a3  a2 |
      | 1  0 | *  | 1  0 |  =   | 1  1 | = | a2  a1 |

A^3 = | 2  1 |    | 1  1 |      | 3  2 |   | a4  a5 |
      | 1  1 | *  | 1  0 |  =   | 2  1 | = | a3  a2 |           

.....

 A^k = | a(k+1)  ak   |   
       | ak      ak-1 |
Time Complexity
Basic: O(n)

Optimized: O(logn)

Strategy
Since we are dealing with A^n, the optimized time complexity of pow(x, n) is O(logn)

A^n =   |A(n/2)^2         | n is even
        |A((n-1)/2)^2 * A | n is odd

A^64 = (A^32)^2 = ((A^16))^2^2 = A^(2^6)
Asymptotic Notation
Comparison of each notation
Compare Function Growth	Compare Numbers	f(n) = 5n	g(n) = n^2
O	<=	f(n) = O(g(n))
o	<	f(n) = o(g(n)
Θ	=	for f(n) = 100n	and g(n) = n + 100
Ω	>=	f(n) = Ω(g(n))	f(n) = Θ(g(n))
ω	>=	f(n) = ω(g(n))
Mathematical Derivation
f(n) = O(g(n))

iff exists constants C and n0
s.t. when n > n0, f(n) <= C * g(n)
lim(n->inf) f(n)/g(n) =     0           | fn = O/o(g(n))
                            constant    | fn = O/Θ/Ω(g(n))
                            inf         | fn = Ω/ω(g(n))
Practice:

lim(n->inf) (100n)/(n+100) = 100 
fn = O/Θ/Ω(g(n))

f(n) = nlgn   g(n) = n^2
f(n) = O/o(g(n))

f(n) = 2^n   g(n) = 3^n
f(n) = O/o(g(n))
lim(n->inf) f(n)/g(n) = lim(n->inf) (2/3)^n = 0

f(n) = n+3   g(n) = 2 * sqrt(n)
f(n) = Ω/ω(g(n))


f(n) = log2(n)   g(n) = log3(n)
f(n) = Ω/ω/Θ(g(n))
lim(n->inf) f(n)/g(n) = lim(n->inf) log2n/log3n = log3/log2

f(n) = (logn)^2   g(n) = log(n^2) = 2logn
f(n) = Ω/ω(g(n))
Master’s Theorem
Idea of merge sort
T(n) = 2T(n/2) + n

             T(n) n                         | n
          /          \
    T(n/2) n/2          T(n/2) n/2          | n
   /     \           /     \
T(n/4)   T(n/4)    T(n/4)   T(n/4)          | n
            ......
T(1)    T(1)    T(1)    T(1) ...            | n
Time Complexity of merge sort
T(n) = height T(level) = logn n = nlogn

Master’s Theorem
T(n) = a * T(n/b) + n^c, where a, b, c are constants

Examples:
T(n) = 2 * T(n/2) + n
T(n) = 8 * T(n/2) + n^2
T(n) = T(n/2) + 1
T(n) = T(n/3) + T(2n/3) + n  (Not master's theorem)
Now we have to compare logb(a) and c

logb(a) > c T(n) = Θ(n^(logb(a)))
logb(a) = c T(n) = Θ((n^c) * logn)
logb(a) < c T(n) = Θ(n^c)
Practice

T(n) = T(n/2) + 1   T(n) = Θ(lgn)
T(n) = 8T(n/2) + n^2   T(n) = Θ(n^3)
T(n) = 7T(n/2) + n^2   T(n) = Θ(n^(log2(7)))
T(n) = 4T(n/2) + n^2   T(n) = Θ(n^2 * (log2n))
T(n) = T(n/2) + n  T(n) = Θ(n)
T(n) = T(n-1) + n  (Not master's theorem)
Draw the Recursion Tree of the last one

Recursion Tree of T(n) = T(n-1) + n 

        T(n) n
        T(n-1) n-1
        T(n-2) n-2
        ...
        T(1) 1




T(n) = 1 + 2 + 3 + ... + n = n(n+1)/2
Θ(n) = n^2
Other useful Summation Formula
1 + 2 + 3 + .. + n = n(n+1)/2

q^0 + q^1 + q^2 + ... q^n = (q^(n+1) -1)/(q-1)

1 + 1/2 + 1/3 + ... + 1/n = Θ(ln(n))
Normal case
T(n) = T(n/3) + T(2n/3) + n

             T(n) n                         | n
          /          \
    T(n/3) n/3        T(2n/3)  2n/3         | n
   /     \           /     \
T(n/9)   T(2n/9)    T(2n/9)   T(4n/9)       | n
            ......
T(1)    T(1)    T(1)    T(1) ...            | n
            /\
           /  \
          /____\
          \     \
            \    \
              \   \
                \_\

left side = log3n
right side = log3/2(n)

T(n) = num of nodes in this recursion tree

n * log3(n) <= T(n) <= n * log3/2(n)
Time Complexity of Normal recursion tree
T(n) = Θ(nlgn)

Some examples
T(n) = T(n/4) + T(3n/4) + n             T(n) = Θ(nlgn)
T(n) = T(n/1000) + T(999n/1000) + n     T(n) = Θ(nlgn)
T(n) = T(n-1) + T(1) + n                T(n) = Θ(n^2)
